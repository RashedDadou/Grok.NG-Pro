# draw.py - Ø£ÙˆÙ„ Ø§Ù„Ù…Ù„Ù
import logging
import math
import cv2
import numpy as np
from datetime import datetime

class Draw:
    def generate_ultimate_fallback(
        self,
        spec: str,
        tasks: list,
        prompt: str,
        resolution: tuple = (1920, 1080),
        is_video: bool = False,
        video_multiplier: float = 1.0,
        context: dict = None
    ) -> tuple[str, str | None]:
        """
        Ø§Ù„Ù€ Ultimate Fallback Renderer Ø§Ù„ÙƒØ§Ù…Ù„ â€“ ÙŠÙˆÙ„Ø¯ ØµÙˆØ±Ø© Ø£Ùˆ ÙÙŠØ¯ÙŠÙˆ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¨ÙƒÙ„ Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¯Ù„Ø¹
        Ø­ØªÙ‰ Ù„Ùˆ Grok API Ù…Ø´ Ù…ØªØ§Ø­. ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ OpenCV + NumPy Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ.
        
        Parameters:
        -----------
        spec : str
            Ø§Ù„ØªØ®ØµØµ (geometric_design, futuristic_design, traditional_design)
        tasks : list
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ù…Ù† auto_specialize_and_generate_tasks (ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù‡Ù†Ø§ØŒ Ø¨Ø³ Ù„Ù„ØªÙˆØ§ÙÙ‚)
        prompt : str
            Ø§Ù„Ù€ prompt Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        resolution : tuple
            (width, height) â€“ Ø§ÙØªØ±Ø§Ø¶ÙŠ 1920x1080
        is_video : bool
            Ù‡Ù„ Ù†ÙˆÙ„Ø¯ ÙÙŠØ¯ÙŠÙˆ Ø£Ù… ØµÙˆØ±Ø© ÙÙ‚Ø·
        video_multiplier : float
            Ù…Ø¶Ø§Ø¹Ù Ù…Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Ù…Ù† simulate_physics_for_tasks)
        context : dict
            Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ (Ù…Ø«Ù„ is_symmetric Ù…Ù† parse_prompt)
        
        Returns:
        --------
        tuple[str, str | None]
            (Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©, Ù…Ø³Ø§Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ None)
        """
        if context is None:
            context = {}

        width, height = resolution

        # 1. Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù…Ø¹ Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ø¯Ø§Ø¡
        MAX_FRAMES = 300
        BASE_FRAMES = 144  # 6 Ø«ÙˆØ§Ù†ÙŠ @ 24fps
        fps = 24

        if is_video:
            desired_frames = int(BASE_FRAMES * video_multiplier)
            total_frames = min(MAX_FRAMES, max(1, desired_frames))
            if desired_frames > MAX_FRAMES:
                logging.info(f"ØªØ­Ø°ÙŠØ± Ø£Ø¯Ø§Ø¡: ØªÙ… ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù…Ù† {desired_frames} Ø¥Ù„Ù‰ {MAX_FRAMES}")
        else:
            total_frames = 1

        lower_prompt = prompt.lower()

        # 2. ÙƒØ´Ù Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ© ÙˆØ§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª
        background_settings = self._detect_background_needs(tasks, lower_prompt)

        # 3. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø«Ø§Ø¨ØªØ©
        stars = self._generate_stars(width, height)

        # 4. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† Ø§Ù„Ù€ prompt
        positions = self._extract_part_positions(lower_prompt)

        # 5. ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª (Ø§Ù„Ø¯Ù„Ø¹ ÙƒÙ„Ù‡ Ù‡Ù†Ø§)
        frames = self._generate_frames(
            width=width,
            height=height,
            total_frames=total_frames,
            stars=stars,
            background_settings=background_settings,
            positions=positions,
            lower_prompt=lower_prompt,
            spec=spec,
            is_video=is_video,
            video_multiplier=video_multiplier,
            context=context  # Ù†Ù…Ø±Ø± Ø§Ù„Ù€ context Ø¹Ø´Ø§Ù† Ø§Ù„ØªÙ…Ø§Ø«Ù„ ÙˆØ§Ù„ØªØ®ØµÙŠØµØ§Øª
        )

        # 6. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§ÙŠØ¬ (ØµÙˆØ±Ø© + ÙÙŠØ¯ÙŠÙˆ Ù„Ùˆ Ù…Ø·Ù„ÙˆØ¨)
        img_path, video_path = self._save_output_frames(frames, spec, is_video, fps, width, height)

        return img_path, video_path

    def _detect_background_needs(self, tasks: list, lower_prompt: str, spec: str = "") -> dict:
        """
        ÙƒØ´Ù Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ© - spec Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù…Ø¹ Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙØ§Ø±ØºØ©
        """
        # Ù…ÙÙŠØ´ Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ù€ if spec is None Ù„Ø£Ù†Ù†Ø§ Ø­Ø¯Ø¯Ù†Ø§Ù‡ Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ ""
    
        # Ù‡Ù„ ÙÙŠ Ø£Ø±Ø¶/Ø·Ø¨ÙŠØ¹Ø©ØŸ
        has_ground = (
            any("nature" in t["name"].lower() or "creature" in t["name"].lower() or "forest" in t["name"].lower() or "tree" in t["name"].lower() or "mountain" in t["name"].lower()
                for t in tasks)
            or any(word in lower_prompt for word in ["ground", "earth", "grass", "forest", "jungle", "nature", "animal", "creature", "organic"])
            or "traditional_design" in spec
        )

        # Ù‡Ù„ ÙÙŠ ÙØ¶Ø§Ø¡/Ù†Ø¨ÙŠÙˆÙ„Ø§/Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØŸ
        has_nebula = (
            any("spaceship" in t["name"].lower() or "hull" in t["name"].lower() or "wing" in t["name"].lower() or "engine" in t["name"].lower()
                for t in tasks)
            or any(word in lower_prompt for word in ["space", "nebula", "galaxy", "stars", "cosmos", "futuristic", "sci-fi", "spaceship", "rocket"])
            or spec == "futuristic_design"
        )

        # Ù‡Ù„ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ø³Ø§ÙŠØ¨Ø±Ø¨Ù†ÙƒØŸ
        has_skyline = (
            any("cybercity" in t["name"].lower() or "tower" in t["name"].lower() or "building" in t["name"].lower() or "neon" in t["name"].lower()
                for t in tasks)
            or any(word in lower_prompt for word in ["city", "cybercity", "cyberpunk", "neon", "skyscraper", "downtown", "urban"])
        )

        # Ù‡Ù„ ÙÙŠ ÙƒØ§Ø¦Ù† ÙŠØ­ØªØ§Ø¬ Ø¸Ù„ØŸ
        has_shadow = (
            any("main" in t["name"].lower() or "object" in t["name"].lower() or "body" in t["name"].lower() or "hull" in t["name"].lower() or "structure" in t["name"].lower()
                for t in tasks)
            or len(tasks) > 0  # Ø£ÙŠ ØªØµÙ…ÙŠÙ… Ù„Ù‡ Ø¸Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ
        )

        logging.info(f"ÙƒØ´Ù Ø§Ù„Ø®Ù„ÙÙŠØ©: ground={has_ground}, nebula={has_nebula}, skyline={has_skyline}, shadow={has_shadow}")

        return {
            "has_ground": has_ground,
            "has_nebula": has_nebula,
            "has_skyline": has_skyline,
            "has_shadow": has_shadow
        }
    
    def _generate_stars(self, width: int, height: int) -> list:
        """
        ØªÙˆÙ„ÙŠØ¯ 500 Ù†Ø¬Ù…Ø© Ù…ØªÙ„Ø£Ù„Ø¦Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¶Ø§Ø¦ÙŠØ© âœ¨
        """
        import numpy as np
        np.random.seed(42)  # Ø¹Ø´Ø§Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© ØªÙƒÙˆÙ† Ø«Ø§Ø¨ØªØ© ÙˆØ¬Ù…ÙŠÙ„Ø© ÙƒÙ„ Ù…Ø±Ø©
        return [(np.random.randint(0, width), np.random.randint(0, height)) for _ in range(500)]

    def _extract_part_positions(self, lower_prompt: str) -> dict:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† Ø§Ù„Ù€ prompt Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… regex Ø°ÙƒÙŠ
        Ù…Ø«Ø§Ù„: "engine on rear", "wing on left" â†’ {'engine': 'rear', 'wing': 'left'}
        """
        import re

        positions = {}
        # Ù†Ù…Ø· regex ÙŠØºØ·ÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        pos_pattern = r'(engine|wing|cockpit|tail|nose|beam|tower|pillar|cabin|fuselage|hull|weapon|shield|core|body|head|arm|leg)\s+(on|at|in|to the)\s+(top|bottom|left|right|center|front|rear|above|below|middle|back|nose|tail|port|starboard)'
        
        for match in re.finditer(pos_pattern, lower_prompt):
            part = match.group(1)
            position = match.group(3)
            positions[part] = position

        logging.info(f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(positions)} Ù…ÙˆÙ‚Ø¹: {positions}")

        return positions

    def _generate_frames(
        self,
        width: int, height: int, total_frames: int,
        stars: list, background_settings: dict,
        positions: dict, lower_prompt: str, spec: str,
        is_video: bool, video_multiplier: float,
        context: dict = None,                     # â† Ø£Ø¶Ù Ø§Ù„Ø³Ø·Ø± Ø¯Ù‡
        asteroid_x_start: int = -400,
        engine_pulse_start: float = 0.0,
        high_complexity: bool = False
    ) -> list:
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù„Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ ÙƒÙ„ Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¯Ù„Ø¹:
        - Ù†Ø¬ÙˆÙ… Ù…ØªÙ„Ø£Ù„Ø¦Ø©
        - Ø®Ù„ÙÙŠØ§Øª Ø°ÙƒÙŠØ© (Ø£Ø±Ø¶ØŒ Ù†Ø¨ÙŠÙˆÙ„Ø§ØŒ Ø³ÙƒØ§ÙŠ Ù„Ø§ÙŠÙ†)
        - Ø£Ø¬Ø²Ø§Ø¡ Ù…ÙƒØªØ´ÙØ© Ù…ÙˆÙ‚Ø¹ÙŠÙ‹Ø§ (Ù…Ø­Ø±ÙƒØ§ØªØŒ Ø£Ø¬Ù†Ø­Ø©ØŒ ÙƒÙˆÙƒØ¨ÙŠØª...)
        - ÙƒØ§Ø¦Ù† Ø±Ø¦ÙŠØ³ÙŠ ÙÙŠ Ø§Ù„ÙˆØ³Ø· Ù„Ùˆ Ù…ÙÙŠØ´ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø­Ø¯Ø¯Ø©
        - Ø¸Ù„ Ø´ÙØ§Ù ÙŠØªÙ†ÙØ³
        - ÙƒÙˆÙŠÙƒØ¨ Ù…ØªØ­Ø±Ùƒ Ù…Ø¹ Ø°ÙŠÙ„ (ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ)
        - ØªØ£Ø«ÙŠØ± ÙƒØ§Ù…ÙŠØ±Ø§ zoom + shake Ù„Ùˆ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø¹Ø§Ù„ÙŠ
        """
        frames = []
        asteroid_x = asteroid_x_start
        engine_pulse = engine_pulse_start

        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¨ØµØ±ÙŠØ© (Ø¨Ø§Ù„Ø¨ÙƒØ³Ù„)
        pos_map = {
            "top": (width // 2, height // 2 - 350),
            "bottom": (width // 2, height // 2 + 350),
            "left": (width // 2 - 450, height // 2),
            "right": (width // 2 + 450, height // 2),
            "center": (width // 2, height // 2),
            "front": (width // 2, height // 2 - 150),
            "rear": (width // 2, height // 2 + 150),
            "above": (width // 2, height // 2 - 250),
            "below": (width // 2, height // 2 + 250),
            "middle": (width // 2, height // 2),
            "back": (width // 2, height // 2 + 200)
        }

        has_ground = background_settings["has_ground"]
        has_nebula = background_settings["has_nebula"]
        has_skyline = background_settings["has_skyline"]
        has_shadow = background_settings["has_shadow"]

        for frame_num in range(total_frames):
            frame = np.zeros((height, width, 3), dtype=np.uint8)
            frame[:] = (8, 0, 35)  # Ø®Ù„ÙÙŠØ© ÙØ¶Ø§Ø¡ Ø¨Ù†ÙØ³Ø¬ÙŠ ØºØ§Ù…Ù‚ Ø¯Ù„Ø¹ Ø¬Ø¯Ù‹Ø§ ğŸ’œ

            # ØªØ£Ø«ÙŠØ± ÙƒØ§Ù…ÙŠØ±Ø§ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ (zoom + shake) Ù„Ùˆ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹Ù‚Ø¯
            if is_video and high_complexity:
                zoom_factor = 1 + 0.15 * math.sin(frame_num / 40)
                shake_x = int(12 * math.sin(frame_num / 15))
                shake_y = int(10 * math.cos(frame_num / 18))

                zoomed_h = int(height / zoom_factor)
                zoomed_w = int(width / zoom_factor)
                temp = np.zeros((height, width, 3), dtype=np.uint8)
                temp[:] = frame

                resized = cv2.resize(temp, (zoomed_w, zoomed_h))
                start_y = (height - zoomed_h) // 2 + shake_y
                start_x = (width - zoomed_w) // 2 + shake_x

                # Ù‚Øµ Ø¢Ù…Ù† Ø¹Ø´Ø§Ù† Ù…Ø§ ÙŠØ­ØµÙ„Ø´ error
                y1 = max(0, start_y)
                y2 = min(height, start_y + zoomed_h)
                x1 = max(0, start_x)
                x2 = min(width, start_x + zoomed_w)

                if y2 > y1 and x2 > x1:
                    frame[y1:y2, x1:x2] = resized[(y1 - start_y):(y2 - start_y), (x1 - start_x):(x2 - start_x)]

            # Ù†Ø¬ÙˆÙ… Ù…ØªÙ„Ø£Ù„Ø¦Ø© âœ¨
            for sx, sy in stars:
                brightness = int(120 + 135 * (math.sin(frame_num / 6 + sx / 60) + 1) / 2)
                brightness = min(255, max(0, brightness))
                cv2.circle(frame, (sx, sy), 2, (brightness, brightness, brightness), -1)

            # Ø®Ù„ÙÙŠØ© Ø£Ø±Ø¶ Ù„Ùˆ traditional
            if has_ground:
                cv2.rectangle(frame, (0, height // 2 + 100), (width, height), (15, 70, 25), -1)
                cv2.rectangle(frame, (0, height // 2 + 50), (width, height // 2 + 100), (30, 100, 40), -1)

            # Ù†Ø¨ÙŠÙˆÙ„Ø§ ÙØ¶Ø§Ø¦ÙŠØ© Ù„Ùˆ futuristic
            if has_nebula:
                cv2.circle(frame, (width // 5, height // 3), 450, (90, 0, 160), -1)
                cv2.circle(frame, (width // 5 + 200, height // 3 - 150), 400, (140, 0, 220), 120)

            # Ø³ÙƒØ§ÙŠ Ù„Ø§ÙŠÙ† Ø³Ø§ÙŠØ¨Ø±Ø¨Ù†Ùƒ
            if has_skyline:
                for i in range(8):
                    x = 50 + i * 220
                    h = 350 + int(100 * math.sin(frame_num / 20 + i))
                    cv2.rectangle(frame, (x, height - h), (x + 160, height), (50, 50, 110), -1)
                    light = 150 + int(105 * math.sin(frame_num / 10 + i))
                    cv2.rectangle(frame, (x + 30, height - h - 250), (x + 130, height - h - 50), (255, 255, light), -1)

            # Ø±Ø³Ù… Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…ÙˆÙ‚Ø¹ÙŠÙ‹Ø§
            for part, pos_key in positions.items():
                x, y = pos_map.get(pos_key, (width // 2, height // 2))

                if "engine" in part:
                    glow = (255, 100 + int(155 * math.sin(engine_pulse)), int(100 + 155 * math.sin(engine_pulse + 0.5)))
                    cv2.ellipse(frame, (x, y), (140, 260), 0, 0, 360, glow, -1)
                    cv2.ellipse(frame, (x, y), (160, 280), 0, 0, 360, (255, 200, 100), 8)
                    engine_pulse += 0.3

                elif "wing" in part:
                    angle = 20 if "left" in pos_key else -20
                    cv2.ellipse(frame, (x, y), (300, 100), angle, 0, 360, (150, 150, 255), -1)

                elif "cockpit" in part or "cabin" in part:
                    cv2.circle(frame, (x, y), 100, (100, 255, 255), -1)
                    cv2.circle(frame, (x, y), 120, (200, 255, 255), 8)

                elif "hull" in part or "fuselage" in part:
                    cv2.ellipse(frame, (x, y), (400, 150), 0, 0, 360, (120, 120, 200), -1)

                else:
                    cv2.ellipse(frame, (x, y), (180, 120), 0, 0, 360, (200, 200, 255), -1)

            # Ù„Ùˆ Ù…ÙÙŠØ´ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø­Ø¯Ø¯Ø© â†’ ÙƒØ§Ø¦Ù† Ø±Ø¦ÙŠØ³ÙŠ ÙÙŠ Ø§Ù„ÙˆØ³Ø·
            if not positions:
                center_x, center_y = width // 2, height // 2
                if "spaceship" in lower_prompt or spec == "futuristic_design":
                    main_color = (120, 120, 255)
                elif "creature" in lower_prompt:
                    main_color = (100, 200, 100)
                else:
                    main_color = (200, 150, 255)
                cv2.ellipse(frame, (center_x, center_y), (600, 250), -10, 0, 360, main_color, 70)

            # Ø¸Ù„ Ø´ÙØ§Ù ÙŠØªÙ†ÙØ³ ØªØ­Øª Ø§Ù„ÙƒØ§Ø¦Ù†
            if has_shadow:
                shadow = frame.copy()
                cv2.ellipse(shadow, (width // 2 + 80, height - 120), (600, 180), 0, 0, 360, (0, 0, 0), -1)
                alpha = 50 + int(40 * math.sin(frame_num / 12))
                frame = cv2.addWeighted(frame, 1.0, shadow, alpha / 255.0, 0)

            # ÙƒÙˆÙŠÙƒØ¨ Ù…ØªØ­Ø±Ùƒ Ù…Ø¹ Ø°ÙŠÙ„ (ÙÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙ‚Ø·)
            if is_video:
                asteroid_x += int(22 * video_multiplier)
                if asteroid_x > width + 500:
                    asteroid_x = -500
                ast_y = height // 4 + int(60 * math.sin(frame_num / 30))
                cv2.circle(frame, (asteroid_x, ast_y), 140, (110, 100, 80), -1)
                for i in range(8):
                    trail_x = asteroid_x - 100 - i * 60
                    trail_alpha = 1 - i / 8
                    thickness = int(50 * trail_alpha)
                    color = (int(170 * trail_alpha), int(150 * trail_alpha), int(100 * trail_alpha))
                    cv2.line(frame, (asteroid_x - 80, ast_y), (trail_x, ast_y + 80), color, thickness)

            frames.append(frame)

        return frames

    def _save_output_frames(self, frames, spec, is_video, fps, width, height):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = f"grokng_{spec}_{timestamp}"

        best_frame_idx = min(80, len(frames) - 1)
        img_path = f"{base_name}.png"
        cv2.imwrite(img_path, frames[best_frame_idx])
        logging.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {img_path}")

        video_path = None
        if is_video and len(frames) > 1:
            video_path = f"{base_name}.mp4"
            out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
            for f in frames:
                out.write(f)
            out.release()
            logging.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: {video_path}")

        return img_path, video_path
