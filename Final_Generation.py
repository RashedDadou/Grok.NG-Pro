# Final_Generation.py
"""
Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙƒØ¨Ø© Ù…Ù† Ø·Ø¨Ù‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (background, midground, foreground)
ÙƒÙ„ Ø·Ø¨Ù‚Ø© ØªÙˆÙ„Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ø±Ùƒ Ù…ØªØ®ØµØµ Ù…Ø®ØªÙ„Ù (environment, geometric, traditional)
ÙŠØ­Ø¯Ø¯ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„prompt ØªØ­Øª Ø¥Ø´Ø±Ø§Ù SuperVisor Ø¨Ø³ÙŠØ·.
"""

from __future__ import annotations
from abc import ABC, abstractmethod
import os
import shutil
import random
import math
import logging
from time import perf_counter
from pathlib import Path
from typing import List, Union, Optional, Dict, Any, Tuple

from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter, ImageSequence
import cv2

from Core_Image_Generation_Engine import CoreImageGenerationEngine
from memory_manager import GenerativeMemoryManager
from layer_plane import PlaneLayer
from contextlib import contextmanager

from generation_result import GenerationResult
from unified_stage_pipeline import UnifiedStagePipeline
from prompt_supervisor import PromptSupervisor

logger = logging.getLogger(__name__)

class LayerEngine(ABC):
    @abstractmethod
    def generate_layer(
        self,
        prompt: str,
        target_size: tuple = (1024, 1024),
        is_video: bool = False,
        as_layer: bool = True,          # Ø´ÙØ§ÙÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        force_refresh: bool = False,
    ) -> GenerationResult:
        pass

    def receive_input(self, prompt: str):
        # Ù„Ùˆ Ù…Ø­ØªØ§Ø¬ buffer Ø¯Ø§Ø®Ù„ÙŠ
        pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø±ÙƒØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† ÙƒÙ„ Ø´ÙŠØ¡ (ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª + Ø§Ù„Ø¯Ù…Ø¬ + Ø§Ù„ØªÙØ§Ø¹Ù„) 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class CompositeEngine(CoreImageGenerationEngine):
    def __init__(self):
        super().__init__()   # Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§ Ù„Ùˆ ÙÙŠÙ‡ ÙˆØ±Ø§Ø«Ø©

        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµØ­ÙŠØ­Ø© Ø§Ù„Ù„ÙŠ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª
        from environment_design_engine import environment_design_engine  # lowercase
        from geometric_design_engine import geometric_design_engine      # lowercase
        from traditional_design_engine import traditionalDesignEngine    # camel case Ø²ÙŠ Ù…Ø§ Ø¹Ù†Ø¯Ùƒ

        # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯Ø© + () Ø¹Ø´Ø§Ù† instance Ø¬Ø¯ÙŠØ¯ Ù„Ùˆ Ø¯Ø§Ù„Ø©
        self.engine_map = {
            "background": environment_design_engine(),   # â† lowercase + ()
            "midground": geometric_design_engine(),      # â† lowercase + ()
            "foreground": traditionalDesignEngine()      # â† camel + ()
        }

        try:
            self.memory_manager = GenerativeMemoryManager()
        except:
            self.memory_manager = None

        self.supervisor = PromptSupervisor(llm_callable=self._dummy_llm_call)

        self.specialization = {
            "name": "composite",
            "description": "Ù…Ø­Ø±Ùƒ Ø¯Ù…Ø¬ Ø·Ø¨Ù‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©",
            "domain": "image_composition"
        }

        # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª (Ù†Ø¸ÙØª Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ø²ÙŠØ§Ø¯Ø§Øª)
        self.input_port = []
        self.tasks = []
        self.dependencies = {}
        self.stats = {"total_generations": 0, "successes": 0, "failures": 0}
        self.layer_opacities = {"background": 255, "midground": 255, "foreground": 255}
        self.interaction_history = []
        self.composite_history = []
        self.error_log = []
        self.performance_log = []
        self.visualization_data = []
        self.debug_mode = True
        self.last_composite_result: Optional[GenerationResult] = None
        self.layer_interaction_data = {}
        self.composite_count = 0
        self.successful_composites = 0
        self.failed_composites = 0
        self.total_composite_time = 0.0
        self.temp_files: List[Union[str, Path]] = []

        logger.info("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ CompositeEngine Ø¨Ù†Ø¬Ø§Ø­")
        
    def import_env_design(self, file_path: str) -> EnvironmentDesignResult:
        """ÙŠÙ‚Ø±Ø£ Ù…Ù„Ù Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØµØ¯Ù‘Ø± Ù…Ù† environment_engine"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ù…Ø±Ø© ØªØ§Ù†ÙŠØ© Ø¥Ù„Ù‰ EnvironmentElement
        elements = [EnvironmentElement(**el) for el in data.get("elements", [])]
        
        return EnvironmentDesignResult(
            success=data["success"],
            elements=elements,
            metadata=data["metadata"],
            message=data["message"],
            design_time_seconds=data["design_time_seconds"]
        )
    
    def _validate_specialization(self):
        pass  # Ø£Ùˆ logger.debug("Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®ØµØµ - Ù…Ø¤Ù‚Øª")

    def _initialize_units(self):
        pass  # Ø£Ùˆ self.units = {} Ù„Ùˆ Ø¹Ø§ÙŠØ²

    def _initialize_memory_manager(self):
        pass  # Ù„Ùˆ Ù…Ø´ Ù…Ø­ØªØ§Ø¬ memory_manager Ø¯Ù„ÙˆÙ‚ØªÙŠ

    def _initialize_additional_state(self):
        pass

    def _run_initial_diagnostics(self):
        pass

    def _log_specialization_details(self):
        logger.info(f"ØªØ®ØµØµ: {self.specialization}")

    def _log_initial_state(self):
        logger.debug("Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© - ØªÙ…")

    def _validate_specialization(self):
        """
        ØªÙ†ÙÙŠØ° Ø¨Ø³ÙŠØ· Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®ØµØµ (placeholder)
        Ø§Ù„Ø£Ø¨ Ø¨ÙŠØ·Ù„Ø¨Ù‡Ø§ØŒ ÙÙ†Ø¹Ø·ÙŠÙ‡ Ø´ÙŠØ¡ ÙŠØ±Ø¶ÙŠÙ‡
        """
        # Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ù‚ÙŠÙ…Ø© specialization Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ Ù‡Ù†Ø§
        if not hasattr(self, 'specialization'):
            self.specialization = "composite"
        
        if self.specialization not in ["composite", "layer_compositor", "unknown"]:
            logger.warning(f"ØªØ®ØµØµ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {self.specialization} â†’ Ø§Ø³ØªØ®Ø¯Ø§Ù… 'composite' Ø§ÙØªØ±Ø§Ø¶ÙŠ")
            self.specialization = "composite"
        
        logger.debug(f"ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®ØµØµ: {self.specialization}")
        
    def legacy_of_sequential_design(
        self,
        environment_result: GenerationResult,      # Ø§Ù„Ù„ÙŠ Ø±Ø¬Ø¹ Ù…Ù† environment_design_engine
        remaining_prompt: str,                     # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù„ÙŠ Ù„Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ (mid + fg)
        camera_angle: str = None,                  # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: ØªØºÙŠÙŠØ± Ø²Ø§ÙˆÙŠØ©
        resolution: tuple = (1024, 1024),
        **kwargs
    ) -> GenerationResult:
        """
        Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù†ØªÙŠØ¬Ø© ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚ â†’ Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙˆØµÙ â†’ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ
        """
        if not environment_result.success:
            return GenerationResult(
                success=False,
                message="ÙØ´Ù„ Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©",
                output_data=None
            )

        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¨ÙŠØ¦Ø©
        env_data = environment_result.output_data or {}
        env_path = env_data.get("preview_path") or env_data.get("path")
        env_prompt = env_data.get("enhanced_prompt", "")

        if not env_path or not Path(env_path).exists():
            logger.warning("Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ¦Ø© ØºÙŠØ± ØµØ§Ù„Ø­ â†’ fallback Ø¨Ø¯ÙˆÙ† Ù…Ø±Ø¬Ø¹")
            env_path = None

        # 2. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù€ master prompt Ø§Ù„ÙƒØ§Ù…Ù„ (Ø£Ùˆ ØªÙ‚Ø³ÙŠÙ…Ù‡)
        full_prompt = f"{env_prompt}\n{remaining_prompt}".strip()

        # 3. Ø¥Ù…Ø§: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ _generate_environment_elements ÙƒØ§Ù…Ù„
        #    Ø£Ùˆ: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ generate_scene_with_new_angle Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠÙ‡ camera_angle
        if camera_angle:
            composite_result = self.generate_scene_with_new_angle(
                env_data=env_data,
                new_camera_prompt=camera_angle,
                reference_temp_path=env_path
            )
        else:
            composite_result = self._generate_environment_elements(
                prompt=full_prompt,
                resolution=resolution,
                force_refresh=kwargs.get("force_refresh", False),
                is_video=kwargs.get("is_video", False)
            )

        # 4. Ø¥Ø¶Ø§ÙØ© metadata Ø¹Ù† Ø§Ù„ØªØ³Ù„Ø³Ù„
        if composite_result.success:
            composite_result.output_data = composite_result.output_data or {}
            composite_result.output_data["sequential_stages"] = {
                "stage1": "environment",
                "stage1_result": env_data,
                "stage2": "composite",
                "stage2_result": composite_result.output_data
            }

        return composite_result

    def _dummy_llm_call(self, prompt: str) -> str:
        """
        Ø¯Ø§Ù„Ø© ÙˆÙ‡Ù…ÙŠØ© Ù…Ø¤Ù‚ØªØ© Ù„Ù€ PromptSupervisor (placeholder)
        Ø¨Ø¹Ø¯ÙŠÙ† Ù‡ØªØ³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ø¯Ø§Ù„Ø© LLM Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ù…Ø«Ù„ Grok API Ø£Ùˆ OpenAI)
        """
        logger.info(f"[dummy_llm_call] prompt: {prompt[:70]}...")
        
        # Ø±Ø¯ ÙˆÙ‡Ù…ÙŠ Ø¨Ø³ÙŠØ· Ø¹Ø´Ø§Ù† Ù†Ø¹Ø¯ÙŠ Ø§Ù„Ø®Ø·Ø£
        return f"Ø±Ø¯ ÙˆÙ‡Ù…ÙŠ Ù…Ù† LLM: {prompt.upper()[:50]}... (placeholder)"
    
    def _needs_physics_interaction(self, prompt: str, results: dict) -> bool:
        lower = prompt.lower()
        keywords = ["collide", "ØªØµØ§Ø¯Ù…", "wind", "Ø±ÙŠØ§Ø­", "gravity", "Ø¬Ø§Ø°Ø¨ÙŠØ©",
                    "multiple objects", "ÙƒØ§Ø¦Ù†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©", "interact", "ØªÙØ§Ø¹Ù„"]
        count_objects = sum(len(r.output_data.get("entities", [])) for r in results.values())
        return any(k in lower for k in keywords) or count_objects > 4

    def compose_sequentially_with_environment_base(
        self,
        full_user_prompt: str,               # Ø§Ù„ÙˆØµÙ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        supervisor_plan: dict = None,        # Ø®Ø·Ø© Ø§Ù„Ù…Ø´Ø±Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        env_resolution: tuple = (1536, 1024),
        final_resolution: tuple = (1536, 1024),
        force_refresh: bool = False,
        save_intermediate: bool = True,
        output_name_prefix: str = "sequential_composite"
    ) -> GenerationResult:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªØ³Ù„Ø³Ù„ÙŠ Ù…Ù†Ø¸Ù…:
        1. Ø¨ÙŠØ¦Ø© Ø£ÙˆÙ„Ø§Ù‹ (Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©)
        2. geometric ÙÙˆÙ‚ Ø§Ù„Ø¨ÙŠØ¦Ø©
        3. traditional ÙÙˆÙ‚ Ø§Ù„Ø§Ø«Ù†ÙŠÙ†
        """
        stage_times = {}
        intermediate_paths = {}
        start_total = perf_counter()

        # â”€â”€â”€ 0. Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ®Ø·ÙŠØ· / Ø§Ù„ØªÙ‚Ø³ÙŠÙ… (Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø´Ø±Ù) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if supervisor_plan is None:
            supervisor_plan = self.supervisor.plan_sequential_layers(full_user_prompt)
            # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ø§Ù„Ù€ plan Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:
            # {
            #   "background": "Ø´Ø§Ø·Ø¦ Ø¨Ø­Ø±ÙŠ ØºØ±ÙˆØ¨ Ø´Ù…Ø³ Ø°Ù‡Ø¨ÙŠØŒ Ø±Ù…Ù„ Ù†Ø§Ø¹Ù…ØŒ Ø£Ù…ÙˆØ§Ø¬ Ù‡Ø§Ø¯Ø¦Ø©ØŒ Ø³Ù…Ø§Ø¡ Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠØ©",
            #   "midground":  "Ø³ÙŠØ§Ø±Ø© ÙØ§Ø®Ø±Ø© Ø³ÙˆØ¯Ø§Ø¡ Ù„Ø§Ù…Ø¹Ø© Ù…ØªÙˆÙ‚ÙØ© Ø¹Ù„Ù‰ Ø§Ù„Ø±Ù…Ù„ØŒ Ø§Ù†Ø¹ÙƒØ§Ø³ Ø§Ù„Ø´Ù…Ø³ Ø¹Ù„ÙŠÙ‡Ø§",
            #   "foreground": "ÙØªØ§Ø© Ø´Ø§Ø¨Ø© ØªØ¬Ù„Ø³ Ø¹Ù„Ù‰ ØºØ·Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ø±Ø©ØŒ Ø´Ø¹Ø± Ø·ÙˆÙŠÙ„ ÙŠØªØ·Ø§ÙŠØ±ØŒ Ù…Ù„Ø§Ø¨Ø³ Ø´Ø§Ø·Ø¦ Ø£Ù†ÙŠÙ‚Ø©"
            # }

        # â”€â”€â”€ 1. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ¦Ø© (Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        env_engine = environment_design_engine()
        env_result = env_engine.generate_layer(
            prompt=supervisor_plan.get("background", full_user_prompt),
            target_size=env_resolution,
            force_refresh=force_refresh,
            as_layer=True   # ÙŠÙØ¶Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ø´ÙØ§ÙØ© Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†ØŒ Ù„ÙƒÙ† ØºØ§Ù„Ø¨Ø§Ù‹ ØºÙŠØ± Ø´ÙØ§ÙØ©
        )

        if not env_result.success:
            return GenerationResult(
                success=False,
                message=f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {env_result.message}",
                total_time=perf_counter() - start_total
            )

        env_path = env_result.output_data.get("preview_path") or env_result.output_data.get("path")
        intermediate_paths["environment"] = env_path
        stage_times["environment"] = env_result.total_time

        # â”€â”€â”€ 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„ÙˆØ³Ø·Ù‰ (geometric / objects) ÙÙˆÙ‚ Ø§Ù„Ø¨ÙŠØ¦Ø© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        geo_engine = geometric_design_engine()
        geo_result = geo_engine.generate_layer(
            prompt=supervisor_plan.get("midground", ""),
            target_size=final_resolution,
            force_refresh=force_refresh,
            as_layer=True,
            reference_image=env_path,          # â† Ù…Ù‡Ù…: Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¨ÙŠØ¦Ø©
            control_strength=0.65,             # Ù‚ÙˆØ© Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø¨ÙŠØ¦Ø©
            depth_control=True                 # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹
        )

        geo_path = geo_result.output_data.get("preview_path") if geo_result.success else None
        if geo_path:
            intermediate_paths["geometric"] = geo_path
            stage_times["geometric"] = geo_result.total_time

        # â”€â”€â”€ 3. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (traditional / characters) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        trad_engine = traditional_design_engine()
        trad_result = trad_engine.generate_layer(
            prompt=supervisor_plan.get("foreground", ""),
            target_size=final_resolution,
            force_refresh=force_refresh,
            as_layer=True,
            reference_image=env_path,          # Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ø±Ø¬Ø¹ Ø£Ø³Ø§Ø³ÙŠ
            secondary_reference=geo_path,      # Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ù…Ø±Ø¬Ø¹ Ø¥Ø¶Ø§ÙÙŠ (Ø¥Ù† ÙˆØ¬Ø¯Øª)
            control_strength=0.75,
            depth_control=True,
            character_consistency=True         # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­Ø±Ùƒ ÙŠØ¯Ø¹Ù… seed Ø£Ùˆ face lock
        )

        trad_path = trad_result.output_data.get("preview_path") if trad_result.success else None
        if trad_path:
            intermediate_paths["traditional"] = trad_path
            stage_times["traditional"] = trad_result.total_time

        # â”€â”€â”€ 4. Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (ØªØ±ØªÙŠØ¨ Ø«Ø§Ø¨Øª: env â†’ geo â†’ trad) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        layer_paths_ordered = {}
        if env_path:    layer_paths_ordered["background"]  = env_path
        if geo_path:    layer_paths_ordered["midground"]   = geo_path
        if trad_path:   layer_paths_ordered["foreground"]  = trad_path

        final_path = self._composite_layers(
            layer_paths=layer_paths_ordered,
            resolution=final_resolution,
            output_name=f"{output_name_prefix}_{int(time.time())}.png"
        )

        total_time = perf_counter() - start_total

        success = bool(final_path and Path(final_path).exists())

        return GenerationResult(
            success=success,
            message="ØªÙ… Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ Ø¨Ù†Ø¬Ø§Ø­" if success else "ÙØ´Ù„ ÙÙŠ Ù…Ø±Ø­Ù„Ø© Ù…Ø§",
            total_time=total_time,
            stage_times=stage_times,
            specialization="sequential_composite",
            output_data={
                "final_path": final_path,
                "intermediate_paths": intermediate_paths,
                "supervisor_plan": supervisor_plan,
                "stages_order": ["environment", "geometric", "traditional"]
            }
        )
       
    def measurement_unit_validator_and_adjuster(
        self,
        layer_results: Dict[str, GenerationResult],  # {"environment": res_env, "geometric": res_geo, "traditional": res_trad}
        base_map_size_km: tuple = (2, 2),            # Ø­Ø¬Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø·ÙˆÙ„ Ã— Ø¹Ø±Ø¶) Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±
        supervisor_rules: Optional[Dict] = None,     # Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ø´Ø±Ù (Ø¥Ø°Ø§ NoneØŒ ÙŠØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ù…Ø´Ø±Ù)
        auto_adjust: bool = True,                    # Ù‡Ù„ Ù†Ø¹Ø¯Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø£Ù… Ù†Ø±ÙØ¹ Ø®Ø·Ø£ ÙÙ‚Ø·ØŸ
        save_adjusted: bool = True                   # Ø­ÙØ¸ Ø§Ù„ØªØµØ§Ù…ÙŠÙ… Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©ØŸ
    ) -> Dict[str, GenerationResult]:
        """
        ÙˆØ­Ø¯Ø© Ù‚ÙŠØ§Ø³: ØªÙÙ‚Ø¯ ÙˆØªØµØ­Ø­ Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø¹
        - Ù…ØªØµÙ„Ø© Ø¨Ø§Ù„Ù…Ø´Ø±Ù Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù†Ø·Ù‚ÙŠØ©/Ø¹Ù„Ù…ÙŠØ©
        - Ù…Ø±Ø§Ø­Ù„: Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ù…Ø¹ (ÙƒÙ„ Ø·Ø¨Ù‚Ø©) + Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø¹ (Ø§Ù„ÙƒÙ„ÙŠ)
        - Ù…Ø«Ø§Ù„: ØªØµØ­ÙŠØ­ ÙØªØ§Ø© 500Ù… Ø¥Ù„Ù‰ ~1.6Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø´Ø±Ù
        """
        if not supervisor_rules:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±Ù Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù‚ÙŠØ§Ø³
            supervisor_rules = self.supervisor.get_scale_rules(layer_results.keys())
            # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ supervisor_rules Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:
            # {
            #   "traditional": {"human_female": {"height_m": (1.5, 1.7), "width_m": (0.4, 0.6)},
            #   "geometric": {"luxury_car": {"length_m": (4.5, 5.5), "width_m": (1.8, 2.0)},
            #   "environment": {"beach_map": {"total_km": (2, 2)}
            # }

        adjusted_results = layer_results.copy()  # Ù†Ø³Ø®Ø© Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
        stage_times = {"pre_compose": 0.0, "post_compose": 0.0}
        errors = []

        # â”€â”€â”€ 1. Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ù…Ø¹: ØªÙÙ‚Ø¯ ÙƒÙ„ Ø·Ø¨Ù‚Ø© Ù…Ù†ÙØµÙ„Ø© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        start_pre = perf_counter()
        for layer_name, result in layer_results.items():
            if not result.success:
                errors.append(f"{layer_name}: Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙØ§Ø´Ù„Ø©")
                continue

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© / Ø§Ù„Ø·Ø¨Ù‚Ø©
            path = result.output_data.get("preview_path") or result.output_data.get("path")
            if not path or not Path(path).exists():
                errors.append(f"{layer_name}: Ù„Ø§ Ù…Ø³Ø§Ø± ØµØ§Ù„Ø­ Ù„Ù„ØªÙÙ‚Ø¯")
                continue

            # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© (Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙÙŠ metadata)
            metadata = result.output_data.get("metadata", {})
            if "dimensions_m" not in metadata:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV Ù„ØªÙ‚Ø¯ÙŠØ± (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒØ´Ù ÙƒÙˆÙ†ØªÙˆØ± / bounding box)
                estimated_dims = self._estimate_object_size_from_image(path, layer_name, supervisor_rules.get(layer_name, {}))
                metadata["dimensions_m"] = estimated_dims
                result.output_data["metadata"] = metadata  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ØªÙŠØ¬Ø©

            # ØªÙÙ‚Ø¯ Ù…Ù‚Ø§Ø¨Ù„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø´Ø±Ù
            rules = supervisor_rules.get(layer_name, {})
            for obj_type, expected_range in rules.items():
                actual = metadata.get("dimensions_m", {}).get(obj_type, {})
                if not actual:
                    continue

                # Ù…Ø«Ø§Ù„: ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø·ÙˆÙ„ (height_m)
                if "height_m" in expected_range:
                    min_h, max_h = expected_range["height_m"]
                    actual_h = actual.get("height_m", 0)
                    if not (min_h <= actual_h <= max_h):
                        errors.append(f"{layer_name} ({obj_type}): Ø·ÙˆÙ„ ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠ ({actual_h}m) - ÙŠØ¬Ø¨ {min_h}-{max_h}m")
                        if auto_adjust:
                            scale_factor = (min_h + max_h) / 2 / actual_h  # Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ù‚Ø§Ø³ Ø§Ù„Ù…Ø±ØºÙˆØ¨
                            adjusted_path = self._adjust_image_scale(path, scale_factor, save_adjusted)
                            if adjusted_path:
                                result.output_data["preview_path"] = adjusted_path
                                metadata["dimensions_m"][obj_type]["height_m"] *= scale_factor
                                logger.info(f"{layer_name}: ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·ÙˆÙ„ Ø¥Ù„Ù‰ {metadata['dimensions_m'][obj_type]['height_m']:.2f}m")

                # Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ Ù„Ù„Ø¹Ø±Ø¶ØŒ Ø§Ù„Ø·ÙˆÙ„ØŒ Ø¥Ù„Ø®...

        stage_times["pre_compose"] = perf_counter() - start_pre

        # â”€â”€â”€ 2. Ø§Ù„Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¤Ù‚Øª (Ù„Ù„ØªÙÙ‚Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø¹) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if errors and not auto_adjust:
            # Ø¥Ø°Ø§ Ø£Ø®Ø·Ø§Ø¡ ÙˆÙ„Ø§ ØªØ¹Ø¯ÙŠÙ„ØŒ Ù†Ø±Ø¬Ø¹ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            return {"adjusted_results": adjusted_results, "errors": errors, "stage_times": stage_times}

        # Ø¬Ù…Ø¹ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
        layer_paths = {name: res.output_data.get("preview_path") for name, res in adjusted_results.items() if res.success}
        final_path = self._composite_layers(layer_paths, base_map_size_km=base_map_size_km)  # Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ± Ù„Ù„Ù‚ÙŠØ§Ø³ Ø§Ù„ÙƒÙ„ÙŠ

        # â”€â”€â”€ 3. Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø¹: ØªÙÙ‚Ø¯ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ Ø§Ù„Ø¹Ø§Ù… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        start_post = perf_counter()
        if final_path:
            # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø§Ù„ÙƒÙ„ÙŠØ© (Ù…Ø«Ù„: Ù‡Ù„ Ø§Ù„ÙØªØ§Ø© Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø³ÙŠØ§Ø±Ø© Ù…Ù†Ø·Ù‚ÙŠØ©ØŸ)
            overall_dims = self._estimate_overall_consistency(final_path, supervisor_rules, base_map_size_km)
            for issue in overall_dims.get("issues", []):
                errors.append(issue)
                if auto_adjust:
                    # Ù…Ø«Ø§Ù„: Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø®Ø·Ø¦Ø© Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„ Ø¹Ø§Ù…
                    logger.warning(f"ØªØµØ­ÙŠØ­ Ø¹Ø§Ù…: {issue}")
                    # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±Ù Ù„Ù‚Ø±Ø§Ø± ØªØµØ­ÙŠØ­
                    self.supervisor.adjust_based_on_issue(issue, adjusted_results)

        stage_times["post_compose"] = perf_counter() - start_post

        # â”€â”€â”€ 5. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        return {
            "adjusted_results": adjusted_results,
            "final_path": final_path,
            "errors": errors,
            "stage_times": stage_times,
            "supervisor_rules_used": supervisor_rules
        }

    def _estimate_object_size_from_image(self, image_path: str, layer_name: str, rules: Dict) -> Dict:
        """
        ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenCV (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒÙˆÙ†ØªÙˆØ± ÙˆÙ…Ø±Ø¬Ø¹ Ù‚ÙˆØ§Ø¹Ø¯)
        """
        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
        if img is None:
            return {}

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return {}

        # Ø£ÙƒØ¨Ø± ÙƒÙˆÙ†ØªÙˆØ± ÙƒÙ…Ø«Ø§Ù„ (Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)
        cnt = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(cnt)

        # ØªÙ‚Ø¯ÙŠØ± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø´Ø±Ù (Ù†Ø³Ø¨Ø© Ø¨ÙƒØ³Ù„Ø§Øª Ø¥Ù„Ù‰ Ù…ØªØ±)
        # Ø§ÙØªØ±Ø§Ø¶: Ù†Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø¨Ø³ÙŠØ·Ø© (pixels per meter) Ù…Ù† Ø§Ù„Ù…Ø´Ø±Ù Ø£Ùˆ Ø¨Ø­Ø«
        ppm = rules.get("pixels_per_meter", 1)  # ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ«Ù‡ Ù…Ù† Ø§Ù„Ù…Ø´Ø±Ù
        estimated = {
            "height_m": h / ppm,
            "width_m": w / ppm
        }

        logger.info(f"{layer_name}: ØªÙ‚Ø¯ÙŠØ± Ù…Ù‚Ø§Ø³Ø§Øª: {estimated}")
        return estimated

    def _adjust_image_scale(self, image_path: str, scale_factor: float, save_adjusted: bool) -> Optional[str]:
        """
        ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© (resize) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø§Ù…Ù„
        """
        img = cv2.imread(image_path)
        if img is None:
            return None

        new_size = (int(img.shape[1] * scale_factor), int(img.shape[0] * scale_factor))
        adjusted_img = cv2.resize(img, new_size, interpolation=cv2.INTER_LANCZOS4)

        if save_adjusted:
            adjusted_path = f"{Path(image_path).stem}_adjusted{Path(image_path).suffix}"
            cv2.imwrite(adjusted_path, adjusted_img)
            return adjusted_path

        return image_path  # Ø¥Ø°Ø§ Ù„Ø§ Ø­ÙØ¸ØŒ Ù†Ø±Ø¬Ø¹ Ø§Ù„Ø£ØµÙ„ÙŠ (Ø£Ùˆ bytes Ù„Ø§Ø­Ù‚Ø§Ù‹)

    def _estimate_overall_consistency(self, final_path: str, rules: Dict, base_map_size_km: tuple) -> Dict:
        """
        ØªÙÙ‚Ø¯ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø¹ (Ù…Ø«Ù„ Ù†Ø³Ø¨Ø© Ø§Ù„ÙØªØ§Ø© Ù„Ù„Ø³ÙŠØ§Ø±Ø©)
        """
        # Ù‡Ù†Ø§ ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„ÙƒÙ„ÙŠØ©ØŒ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ø³Ø¨
        # Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·: Ø§ÙØªØ±Ø§Ø¶ Ù†Ø³Ø¨Ø© Ù…Ù‚Ø§Ø³Ø§Øª
        issues = []
        # ... ÙƒÙˆØ¯ ØªØ­Ù„ÙŠÙ„ ...
        if len(issues) == 0:
            issues.append("ÙƒÙ„ Ø´ÙŠØ¡ Ù…Ù†Ø·Ù‚ÙŠ")

        return {"issues": issues}

    def _call_layer_engine(self, layer_name, sub_prompt, resolution, force_refresh, is_video, reference_path=None):
        engine_class = self.engine_map.get(layer_name)
        if not engine_class:
            return GenerationResult(success=False, message=f"Ù„Ø§ Ù…Ø­Ø±Ùƒ Ù„Ù„Ø·Ø¨Ù‚Ø©: {layer_name}")

        engine = engine_class()
        
        # Ù…Ø±ÙˆÙ†Ø© Ø£ÙƒØ¨Ø± ÙÙŠ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù€ reference
        extra_kwargs = {}
        if reference_path:
            extra_kwargs.update({
                "reference_image": reference_path,
                "control_strength": 0.70 if layer_name == "midground" else 0.85,  # Ù‚ÙˆØ© Ù…Ø®ØªÙ„ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ø·Ø¨Ù‚Ø©
                "use_depth": layer_name != "foreground",                       # foreground Ø£Ù‚Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ depth
                "use_ip_adapter": layer_name == "foreground"                   # Ù„Ù„Ø´Ø®ØµÙŠØ§Øª
            })

        try:
            result = engine.generate_layer(
                prompt=sub_prompt,
                target_size=resolution,
                force_refresh=force_refresh,
                as_layer=True,
                is_video=is_video,
                **extra_kwargs
            )
            return result
        except Exception as e:
            logger.exception(f"ÙØ´Ù„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù…Ø­Ø±Ùƒ {layer_name}")
            return GenerationResult(success=False, message=str(e))

    def generate_scene_with_new_angle(self, env_result: GenerationResult, new_camera_prompt: str, **kwargs):
        if not env_result.success:
            return GenerationResult(success=False, message="Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙØ´Ù„Øª")

        env_path = self._extract_layer_path(env_result)
        if not env_path:
            return GenerationResult(success=False, message="Ù„Ø§ Ù…Ø³Ø§Ø± Ù…Ø±Ø¬Ø¹ÙŠ Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø©")

        with temp_reference_image(env_path) as ref_path:
            adjusted_prompt = f"{env_result.output_data.get('enhanced_prompt', '')}, {new_camera_prompt}"
            
            # Ø§Ø³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø£Ùˆ Ù…Ø­Ø±Ùƒ Ø¹Ø§Ù… Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
            return self._call_layer_engine(
                layer_name="composite",  # Ø£Ùˆ Ù…Ø­Ø±Ùƒ Ø®Ø§Øµ Ø¥Ø°Ø§ ÙˆØ¬Ø¯
                sub_prompt=adjusted_prompt,
                resolution=kwargs.get("resolution", (1024, 1024)),
                force_refresh=kwargs.get("force_refresh", False),
                is_video=kwargs.get("is_video", False),
                reference_path=ref_path
            )

    def _generate_sequential_layers(self, plan, resolution, force_refresh, is_video):
        results = {}
        reference = None
        stages = [
            ("background", plan.get("background", ""), 0.0),   # Ù‚ÙˆØ© reference = 0 ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            ("midground", plan.get("midground", ""), 0.65),
            ("foreground", plan.get("foreground", ""), 0.80)
        ]

        for layer_name, sub_prompt, ref_strength in stages:
            logger.info(f"[Sequential] Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ {layer_name} | ref_strength={ref_strength}")
            result = self._call_layer_engine(
                layer_name, sub_prompt, resolution, force_refresh, is_video, reference
            )
            results[layer_name] = result
            
            new_ref = self._extract_layer_path(result)
            if new_ref:
                reference = new_ref  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±Ø¬Ø¹ Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            
            if not result.success:
                logger.warning(f"[Sequential] ÙØ´Ù„ {layer_name} â†’ Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø¯ÙˆÙ†Ù‡Ø§")

        return results

    def _simulate_layer_interactions(self, components: Dict[str, str], layer_paths: Dict[str, str]) -> Dict[str, Any]:
        result = {"influence": 0.0, "adjusted_opacities": {}, "notes": [], "z_adjustments": {}}

        full_lower = " ".join(components.values()).lower()
        relations = {
            "on_top": any(w in full_lower for w in ["Ø¹Ù„Ù‰", "ÙÙˆÙ‚", "Ø±Ø§ÙƒØ¨", "Ø¬Ø§Ù„Ø³ Ø¹Ù„Ù‰"]),
            "under": any(w in full_lower for w in ["ØªØ­Øª", "Ø¯Ø§Ø®Ù„", "Ù…ØºØ·Ù‰"]),
            "holding": any(w in full_lower for w in ["ØªÙ…Ø³Ùƒ", "ØªØ­Ù…Ù„"])
        }

        if relations["on_top"]:
            result["notes"].append("Ø¹Ù„Ø§Ù‚Ø©: ÙƒØ§Ø¦Ù† ÙÙŠ foreground ÙÙˆÙ‚ midground")
            result["adjusted_opacities"]["midground"] = 220  # Ø£Ù‚Ù„ Ø´ÙˆÙŠØ© Ø¹Ø´Ø§Ù† ÙŠØ¨Ø§Ù† Ø§Ù„Ø®Ù„Ù
            result["z_adjustments"]["foreground"] = 10       # Ø£Ø¹Ù„Ù‰ z-index

        # Ø¥Ø¶Ø§ÙØ§Øª Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹ (shadows, occlusion hints...)
        result["influence"] = len(result["notes"]) * 0.3  # Ù‚ÙŠÙ…Ø© Ø±Ù…Ø²ÙŠØ©

        return result
    
    def _split_prompt_into_layers(self, prompt: str) -> Dict[str, str]:
        if not self.supervisor:
            return self._fallback_keyword_split(prompt)  # Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙƒÙ€ fallback

        try:
            split_result = self.supervisor.split_into_layers(
                prompt,
                layer_names=["background", "midground", "foreground"],
                instructions="Extract and separate the prompt into three spatial layers: background (environment), midground (large objects), foreground (characters/details). Return JSON with keys: background, midground, foreground."
            )
            # Ø§ÙØªØ±Ø¶ Ø£Ù† supervisor ÙŠØ±Ø¬Ø¹ dict Ù…Ø¨Ø§Ø´Ø±Ø©
            return split_result
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ ØªÙ‚Ø³ÙŠÙ… LLM: {e} â†’ Ø§Ø³ØªØ®Ø¯Ø§Ù… fallback")
            return self._fallback_keyword_split(prompt)

    def _fallback_keyword_split(self, prompt: str) -> Dict[str, str]:
        # Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø§Ù„Ù„ÙŠ Ø¹Ù†Ø¯ÙƒØŒ Ø¨Ø³ Ù†Ø¸ÙÙ‡Ø§ Ø´ÙˆÙŠØ© (Ø£Ø¶Ù Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… re Ø£ÙØ¶Ù„)
        # ... Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª ...
        pass
    
    def _determine_layer_order(self, components: Dict) -> List[str]:
        default_order = ["background", "midground", "foreground"]
        
        # Ù„Ùˆ Ù…ÙÙŠØ´ Ù…Ø­ØªÙˆÙ‰ ÙÙŠ Ø·Ø¨Ù‚Ø© â†’ Ù†Ø­Ø°ÙÙ‡Ø§ Ù…Ù† Ø§Ù„ØªØ±ØªÙŠØ¨
        order = [layer for layer in default_order if components.get(layer, "").strip()]
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠÙ‡ Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ø£Ù…Ø§Ù…ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹ (Ù†Ø§Ø¯Ø±)
        full_text = " ".join(components.values()).lower()
        if any(w in full_text for w in ["ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹", "foreground first", "closest object"]):
            order.reverse()  # Ù†Ø§Ø¯Ø±ØŒ Ø¨Ø³ Ù…Ù…ÙƒÙ†

        return order or default_order    
    
    def _composite_layers(
        self,
        layer_paths: Dict[str, str],
        resolution: tuple = (1024, 1024),
        output_name: Optional[str] = None,
        background_color: tuple = (0, 0, 0, 255),
        layer_opacities: Optional[Dict[str, int]] = None,
        vignette_strength: float = 0.7,
        contrast_boost: float = 1.15
    ) -> str:
        from pathlib import Path
        import os

        # 5. placeholder Ù†ÙŠÙˆÙ† Ø¨Ø³ÙŠØ· (Ù…Ø¯ÙŠÙ†Ø© + Ø³ÙŠØ§Ø±Ø© + ÙØªØ§Ø©) â€“ Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ù…Ø¬ Ø¨ØµØ±ÙŠ
        from PIL import Image, ImageDraw, ImageFilter, ImageEnhance, ImageFont
        import random

        img = Image.new("RGB", resolution, (8, 4, 25))  # Ø®Ù„ÙÙŠØ© Ù†ÙŠÙˆÙ† Ø¯Ø§ÙƒÙ†Ø©
        draw = ImageDraw.Draw(img)

        # Ø®Ø·ÙˆØ· Ù†ÙŠÙˆÙ† Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ù…Ø¯ÙŠÙ†Ø©)
        for _ in range(60):
            x1, y1 = random.randint(0, resolution[0]), random.randint(0, resolution[1])
            x2, y2 = random.randint(0, resolution[0]), random.randint(0, resolution[1])
            color = random.choice([(255, 80, 255), (80, 255, 255), (255, 255, 120), (120, 255, 255)])
            draw.line((x1, y1, x2, y2), fill=color, width=random.randint(1, 4))

        # Ù…Ø¨Ø§Ù†ÙŠ Ù†ÙŠÙˆÙ† Ø¨Ø³ÙŠØ·Ø© (Ø®Ù„ÙÙŠØ©)
        for x in range(50, resolution[0], 150):
            h = random.randint(200, 500)
            draw.rectangle((x, resolution[1]-h, x+80, resolution[1]), fill=(20, 10, 60), outline=random.choice([(255,100,255),(100,255,255)]))
            # Ù†ÙˆØ§ÙØ° Ù…Ø¶ÙŠØ¦Ø©
            for y in range(resolution[1]-h+20, resolution[1]-20, 40):
                draw.rectangle((x+10, y, x+30, y+20), fill=random.choice([(255,200,255),(200,255,255)]))

        # Ø³ÙŠØ§Ø±Ø© Ø±ÙŠØ§Ø¶ÙŠØ© (ÙˆØ³Ø· Ø§Ù„ØµÙˆØ±Ø©)
        car_x = resolution[0] // 2
        car_y = resolution[1] // 2 + 100
        draw.rectangle((car_x - 160, car_y - 60, car_x + 160, car_y + 60), fill=(180, 0, 60), outline=(255, 200, 255), width=5)
        draw.ellipse((car_x - 120, car_y + 40, car_x - 80, car_y + 80), fill=(30, 30, 30))   # Ø¹Ø¬Ù„Ø© ÙŠØ³Ø§Ø±
        draw.ellipse((car_x + 80, car_y + 40, car_x + 120, car_y + 80), fill=(30, 30, 30))  # Ø¹Ø¬Ù„Ø© ÙŠÙ…ÙŠÙ†
        draw.polygon([(car_x - 120, car_y - 60), (car_x, car_y - 120), (car_x + 120, car_y - 60)], fill=(220, 40, 120))  # Ø³Ù‚Ù/Ø²Ø¬Ø§Ø¬
        draw.line((car_x - 160, car_y + 30, car_x - 220, car_y + 10), fill=(255, 255, 150), width=8)  # Ø®Ø· Ø³Ø±Ø¹Ø© ÙŠØ³Ø§Ø±
        draw.line((car_x + 160, car_y + 30, car_x + 220, car_y + 10), fill=(255, 255, 150), width=8)  # Ø®Ø· Ø³Ø±Ø¹Ø© ÙŠÙ…ÙŠÙ†

        # ÙØªØ§Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© (Ø£Ø³ÙÙ„ Ø§Ù„ÙˆØ³Ø·)
        girl_x = resolution[0] // 2
        girl_y = resolution[1] - 220
        draw.ellipse((girl_x - 60, girl_y - 120, girl_x + 60, girl_y - 30), fill=(255, 220, 200))  # ÙˆØ¬Ù‡
        draw.rectangle((girl_x - 70, girl_y - 30, girl_x + 70, girl_y + 140), fill=(80, 0, 160))  # ÙØ³ØªØ§Ù†/Ø¬Ø³Ù…
        draw.polygon([(girl_x - 60, girl_y - 100), (girl_x - 100, girl_y - 150), (girl_x - 20, girl_y - 150)], fill=(220, 100, 255))  # Ø´Ø¹Ø± ÙŠØ³Ø§Ø±
        draw.polygon([(girl_x + 60, girl_y - 100), (girl_x + 100, girl_y - 150), (girl_x + 20, girl_y - 150)], fill=(220, 100, 255))  # Ø´Ø¹Ø± ÙŠÙ…ÙŠÙ†
        draw.ellipse((girl_x - 25, girl_y - 90, girl_x + 25, girl_y - 60), fill=(0, 0, 0))  # Ø¹ÙŠÙˆÙ†
        draw.arc((girl_x - 40, girl_y - 60, girl_x + 40, girl_y - 30), 0, 180, fill=(255, 150, 150), width=3)  # Ø§Ø¨ØªØ³Ø§Ù…Ø©

        # Ù†Øµ ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ (Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ù…Ø¬)
        try:
            font = ImageFont.truetype("arial.ttf", 60)  # Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯
        except:
            font = ImageFont.load_default()
        draw.text((50, 40), "Neon Cyberpunk Test â€“ Ù…Ø¶Ø±Ø³ Engine ğŸ˜", fill=(255, 100, 255), font=font)

        # ØªØ­Ø³ÙŠÙ†Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ© (glow + contrast)
        img = img.filter(ImageFilter.GaussianBlur(3))
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.6)
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(1.3)

        final_path = output_name or f"neon_test_{int(perf_counter()*1000)}.png"
        img.save(final_path)
        self.temp_files.append(final_path)

        total_time = perf_counter() - start_total
        logger.info(f"ØªÙ… Ø­ÙØ¸ placeholder Ù†ÙŠÙˆÙ† Ø¨Ø³ÙŠØ·: {final_path}")

        try:
            if not is_gif:
                # â”€â”€â”€ ØµÙˆØ±Ø© Ø«Ø§Ø¨ØªØ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                base = Image.new("RGBA", resolution, background_color)

                # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ù…Ù† Ø§Ù„Ø®Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù…Ø§Ù…
                for layer_name in ["background", "midground", "foreground"]:
                    res = layer_results.get(layer_name)
                    if not res or not res.success:
                        logger.debug(f"Ø·Ø¨Ù‚Ø© {layer_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ ÙØ´Ù„Øª â†’ ØªØ®Ø·ÙŠ")
                        continue

                    out = res.output_data or {}
                    layer_img = None

                    # Ø§Ù„Ø­Ø§Ù„Ø© 1: ØµÙˆØ±Ø© Ø¬Ø§Ù‡Ø²Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©)
                    for key in ["preview_path", "color", "path"]:
                        p = out.get(key)
                        if p and os.path.exists(p):
                            try:
                                layer_img = Image.open(p).convert("RGBA").resize(resolution, Image.Resampling.LANCZOS)
                                logger.info(f"Ø¯Ù…Ø¬ ØµÙˆØ±Ø© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù€ {layer_name} Ù…Ù†: {p}")
                                break
                            except Exception as e:
                                logger.warning(f"ÙØ´Ù„ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ {layer_name}: {e}")
                                continue

                    # Ø§Ù„Ø­Ø§Ù„Ø© 2: ØªØµÙ…ÙŠÙ… ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØµÙˆØ±Ø© Ø¬Ø§Ù‡Ø²Ø©)
                    if layer_img is None and "assets_directory" in out:
                        logger.info(f"ØªÙˆÙ„ÙŠØ¯ placeholder Ù„ØªØµÙ…ÙŠÙ… {layer_name} Ù…Ù† Ù…Ø¬Ù„Ø¯: {out['assets_directory']}")
                        layer_img = self._render_design_placeholder(
                            design_data=out,
                            resolution=resolution,
                            layer_name=layer_name
                        )

                    if layer_img is None:
                        logger.warning(f"Ù„Ø§ ØµÙˆØ±Ø© ÙˆÙ„Ø§ ØªØµÙ…ÙŠÙ… ØµØ§Ù„Ø­ Ù„Ù„Ø·Ø¨Ù‚Ø© {layer_name} â†’ ØªØ®Ø·ÙŠ")
                        continue

                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø´ÙØ§ÙÙŠØ©
                    opacity = layer_opacities.get(layer_name, 255)
                    if opacity < 255:
                        alpha = layer_img.split()[3]
                        alpha = ImageEnhance.Brightness(alpha).enhance(opacity / 255.0)
                        layer_img.putalpha(alpha)

                    base = Image.alpha_composite(base, layer_img)

                # ØªØ£Ø«ÙŠØ±Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
                base = self._apply_post_effects(base, vignette_strength, contrast_boost)

                if not output_name:
                    output_name = f"composite_{int(perf_counter() * 1000)}.png"

                base.save(output_name, "PNG", optimize=True)
                logger.info(f"[Composite PNG] ØªÙ… Ø§Ù„Ø­ÙØ¸: {output_name}")
                return output_name

            else:
                # â”€â”€â”€ GIF Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                logger.info("[GIF Composite] Ø¨Ø¯Ø¡ Ø¯Ù…Ø¬ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª...")

                layer_frames = {}
                max_frames = 0
                durations = []

                for layer_name in ["background", "midground", "foreground"]:
                    res = layer_results.get(layer_name)
                    if not res or not res.success:
                        continue

                    out = res.output_data or {}
                    path = out.get("preview_path") or out.get("color")

                    if path and os.path.exists(path):
                        img = Image.open(path)
                        if img.format == 'GIF':
                            frames = [f.convert("RGBA").resize(resolution, Image.Resampling.LANCZOS)
                                      for f in ImageSequence.Iterator(img)]
                            layer_frames[layer_name] = frames
                            max_frames = max(max_frames, len(frames))
                            durations.append(img.info.get('duration', 100))
                        else:
                            frame = img.convert("RGBA").resize(resolution, Image.Resampling.LANCZOS)
                            layer_frames[layer_name] = [frame] * max_frames  # ØªÙƒØ±Ø§Ø± Ù„Ù„Ø¥Ø·Ø§Ø±Ø§Øª

                    elif "assets_directory" in out:
                        # ØªØµÙ…ÙŠÙ… ÙÙ‚Ø· â†’ placeholder Ø«Ø§Ø¨Øª Ù…ÙƒØ±Ø±
                        placeholder = self._render_design_placeholder(out, resolution, layer_name)
                        layer_frames[layer_name] = [placeholder] * 12  # 12 Ø¥Ø·Ø§Ø± Ø§ÙØªØ±Ø§Ø¶ÙŠ
                        max_frames = max(max_frames, 12)
                        durations.append(100)

                if not layer_frames:
                    raise ValueError("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª Ø£Ùˆ ØªØµØ§Ù…ÙŠÙ… ØµØ§Ù„Ø­Ø© Ù„Ù„Ù€ GIF")

                frame_duration = min((d for d in durations if d > 0), default=100)

                composite_frames = []
                for i in range(max_frames):
                    base = Image.new("RGBA", resolution, background_color)
                    for layer_name in ["background", "midground", "foreground"]:
                        frames = layer_frames.get(layer_name, [])
                        if not frames:
                            continue
                        frame = frames[min(i, len(frames)-1)]

                        opacity = layer_opacities.get(layer_name, 255)
                        if opacity < 255:
                            alpha = frame.split()[3]
                            alpha = ImageEnhance.Brightness(alpha).enhance(opacity / 255.0)
                            frame.putalpha(alpha)

                        base = Image.alpha_composite(base, frame)

                    base = self._apply_post_effects(base, vignette_strength, contrast_boost)
                    composite_frames.append(base)

                if not output_name:
                    output_name = f"composite_{int(perf_counter() * 1000)}.gif"

                composite_frames[0].save(
                    output_name,
                    save_all=True,
                    append_images=composite_frames[1:],
                    duration=frame_duration,
                    loop=0,
                    optimize=True,
                    disposal=2
                )
                logger.info(f"[GIF] ØªÙ… Ø§Ù„Ø­ÙØ¸: {output_name} ({len(composite_frames)} Ø¥Ø·Ø§Ø±)")
                return output_name

        except Exception as e:
            logger.exception("ÙØ´Ù„ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
            error_img = Image.new("RGBA", resolution, (200, 50, 50, 255))
            draw = ImageDraw.Draw(error_img)
            draw.text((20, 20), f"Composite Error:\n{str(e)[:120]}", fill=(255, 255, 255))
            error_path = f"error_{int(perf_counter()*1000)}.png"
            error_img.save(error_path)
            return error_path
                
    def _apply_post_effects(self, img: Image.Image, vignette: float = 0.7, contrast: float = 1.15) -> Image.Image:
        from PIL import ImageEnhance, ImageFilter, ImageDraw, ImageChops

        # 1. Contrast & brightness boost
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(contrast)

        # 2. Vignette (ØªØ¹ØªÙŠÙ… Ø§Ù„Ø­ÙˆØ§Ù)
        if vignette > 0:
            mask = Image.new("L", img.size, 255)
            draw = ImageDraw.Draw(mask)
            width, height = img.size
            for i in range(0, 256):
                alpha = int(255 * (1 - vignette * (i / 255) ** 2))
                draw.rectangle(
                    (i, i, width - i, height - i),
                    fill=max(0, alpha)
                )
            vignette_layer = Image.new("RGBA", img.size, (0, 0, 0, 0))
            vignette_layer.putalpha(mask)
            img = Image.composite(img, ImageChops.multiply(img, vignette_layer), mask)

        # 3. optional: slight sharpening
        img = img.filter(ImageFilter.UnsharpMask(radius=1.0, percent=150, threshold=3))

        return img

    def generate(self, prompt: str, as_layer: bool = False, target_size: tuple = (1024, 1024)) -> str:
        """
        Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø£Ùˆ Ø·Ø¨Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ®ØµØµ
        ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© â†’ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø³ÙŠØ·Ø© Ù…Ø¹ Ù†Øµ ÙÙ‚Ø·
        Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø³ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ù…Ø­Ø±ÙƒØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© (Ù…Ø«Ù„ Stable Diffusion Ø£Ùˆ ØºÙŠØ±Ù‡)
        """
        from PIL import Image, ImageDraw, ImageFont

        logger.warning("[Placeholder] Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙˆÙ„ÙŠØ¯ ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¨Ø³ÙŠØ· â€“ ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ù…Ø­Ø±Ùƒ Ø­Ù‚ÙŠÙ‚ÙŠ")
        
        img = Image.new("RGBA", target_size, (0, 0, 0, 0) if as_layer else (255, 255, 255, 255))
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.truetype("arial.ttf", 40)
        except:
            font = ImageFont.load_default()
        text = f"{self.specialization.get('name', 'unknown')}\n{prompt[:50]}..."
        draw.text((20, 20), text, fill=(255, 0, 0), font=font)
        output_name = f"{self.specialization.get('name', 'unknown')}_{int(perf_counter() * 1000)}.png"
        img.save(output_name, "PNG", optimize=True)
        self.temp_files.append(output_name)
        return output_name        
                    
    def create_layer_image(
        specialization: str,
        prompt: str = "",
        width: int = 1024,
        height: int = 1024,
        transparent_bg: bool = True,
        target_opacity: int = 255,
        is_video: bool = False
    ) -> Optional[str]:
        """
        Placeholder Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© Ø¨Ø³ÙŠØ·Ø© (fallback Ø­ØªÙ‰ Ø±Ø¨Ø· Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)
        """
        try:
            from PIL import Image, ImageDraw, ImageFont
            import random

            mode = "RGBA" if transparent_bg else "RGB"
            bg_color = (0, 0, 0, 0) if transparent_bg else (10, 12, 25)
            img = Image.new(mode, (width, height), bg_color)
            draw = ImageDraw.Draw(img)

            lower_prompt = prompt.lower()

            if specialization == "traditional_design":
                # Ø£Ø´Ø¬Ø§Ø± + Ø¶Ø¨Ø§Ø¨ + ÙƒØ§Ø¦Ù† (Ø­ØµØ§Ù† + Ø±Ø§ÙƒØ¨ Ø¥Ø°Ø§ ÙˆØ¬Ø¯)
                for _ in range(15):
                    x = random.randint(-50, width + 50)
                    h = random.randint(400, height - 100)
                    draw.polygon([(x-100, height), (x, height - h), (x+100, height)], fill=(8, 12, 20))

                for _ in range(40):
                    x, y = random.randint(0, width), random.randint(0, height // 2 + 100)
                    r = random.randint(100, 300)
                    draw.ellipse((x-r, y-r, x+r, y+r), fill=(200, 210, 240, 30))

                if any(kw in lower_prompt for kw in ["horse", "Ø­ØµØ§Ù†", "creature"]):
                    cx, cy = width // 2, height - 180
                    draw.ellipse((cx-90, cy-70, cx+90, cy+70), fill=(220, 220, 240))  # Ø¬Ø³Ù…
                    draw.ellipse((cx-40, cy-110, cx+40, cy-30), fill=(220, 220, 240))  # Ø±Ø£Ø³
                    draw.ellipse((cx-15, cy-80, cx-5, cy-70), fill=(0,0,0))           # Ø¹ÙŠÙ† ÙŠØ³Ø§Ø±
                    draw.ellipse((cx+5, cy-80, cx+15, cy-70), fill=(0,0,0))           # Ø¹ÙŠÙ† ÙŠÙ…ÙŠÙ†
                    draw.rectangle((cx-35, cy-160, cx+35, cy-80), fill=(180, 140, 100))  # Ø±Ø§ÙƒØ¨

                for _ in range(80):
                    x = random.randint(0, width)
                    y = random.randint(0, height)
                    sz = random.randint(3, 9)
                    alpha = random.randint(80, 180)
                    draw.ellipse((x-sz, y-sz, x+sz, y+sz), fill=(230, 240, 255, alpha))

            elif specialization == "geometric_design":
                center_x, center_y = width // 2, height // 2
                for r in range(60, 400, 45):
                    draw.ellipse((center_x - r, center_y - r, center_x + r, center_y + r), outline=(180, 160, 120), width=3)

                for angle in range(0, 360, 15):
                    rad = math.radians(angle)
                    x2 = center_x + 500 * random.uniform(0.6, 1.0) * math.cos(rad)
                    y2 = center_y + 500 * random.uniform(0.6, 1.0) * math.sin(rad)
                    draw.line((center_x, center_y, x2, y2), fill=(220, 190, 80), width=2)

            elif specialization == "environment_design":
                draw.rectangle((0, 0, width, height), fill=(5, 5, 15))
                for y in range(80, height, 140):
                    draw.line((0, y, width, y), fill=(0, 255, 220, 140), width=3)
                for x in range(100, width, 180):
                    draw.line((x, 0, x, height), fill=(255, 80, 220, 130), width=3)
                for _ in range(25):
                    x, y = random.randint(0, width), random.randint(0, height)
                    r = random.randint(40, 180)
                    draw.ellipse((x-r, y-r, x+r, y+r), fill=(0, 240, 255, 45))

            else:
                draw.text((width//4, height//2), f"Layer: {specialization}\n{prompt[:60]}", fill=(200, 200, 255))

            # ØªØ·Ø¨ÙŠÙ‚ opacity ÙƒÙ„ÙŠ
            if target_opacity < 255 and mode == "RGBA":
                alpha = Image.new("L", img.size, target_opacity)
                img.putalpha(alpha)

            # Ø­ÙØ¸
            suffix = "video" if is_video else "layer"
            ts = int(perf_counter() * 1000)
            output_path = f"{specialization}_{suffix}_{ts}.png"
            img.save(output_path, "PNG", optimize=True)

            logger.info(f"[Placeholder] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© {specialization} â†’ {output_path}")
            return output_path

        except Exception as e:
            logger.exception(f"ÙØ´Ù„ placeholder Ù„Ù€ {specialization}")
            return None
        
    def generate_image(
        self,
        specialization: Optional[str] = None,
        is_video: bool = False,
        force_refresh: bool = False,
        as_layer: bool = False,
        target_size: tuple = (1024, 1024)
    ) -> GenerationResult:
        """
        Ø¯Ø§Ù„Ø© Ø§Ù†ØªÙ‚Ø§Ù„ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ Ø·Ø¨Ù‚Ø© Ø£Ùˆ ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø© (fallback Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ·ÙˆÙŠØ±)
        ÙŠÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… _generate_environment_elements Ø£Ùˆ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ®ØµØµØ© Ù…Ø¨Ø§Ø´Ø±Ø©
        """
        spec_name = specialization or self.specialization.get("name", "unknown")
        logger.warning(f"[DEPRECATED] Ø§Ø³ØªØ®Ø¯Ø§Ù… generate_image (fallback) â†’ spec={spec_name} | layer={as_layer}")

        start_total = perf_counter()
        stage_times = {}

        # Ø¥Ø°Ø§ Ù…ÙÙŠØ´ prompt Ù…ØªØ±Ø§ÙƒÙ… â†’ ÙØ´Ù„
        if not self.input_port:
            return GenerationResult(
                success=False,
                message="Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ ÙÙŠ input_port",
                total_time=0.0,
                stage_times={},
                specialization=spec_name,
                is_video=is_video
            )

        full_prompt = " ".join(self.input_port).strip()

        try:
            t_render = perf_counter()

            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªØ®ØµØµ Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯
            if specialization and specialization in self.engine_map:
                engine_class = self.engine_map[specialization]
                engine = engine_class()
                layer_result = engine.generate_layer(
                    prompt=full_prompt,
                    target_size=target_size,
                    force_refresh=force_refresh,
                    as_layer=as_layer,
                    is_video=is_video
                )
                if layer_result.success:
                    path = self._extract_layer_path(layer_result)  # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø±Ù†Ø©
                    if path:
                        preview_path = path
                    else:
                        preview_path = None
                else:
                    preview_path = None
            else:
                # fallback Ù„Ù€ placeholder PIL
                preview_path = self._create_simple_image(
                    {"raw_prompt": full_prompt},
                    is_video=is_video,
                    transparent_bg=as_layer,
                    target_size=target_size
                )

            stage_times["rendering"] = perf_counter() - t_render

            if not preview_path:
                raise ValueError("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø§ÙŠÙ†Ø©")

            total_time = perf_counter() - start_total

            return GenerationResult(
                success=True,
                message="ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (Ø§Ù†ØªÙ‚Ø§Ù„ÙŠ)" + (" Ø·Ø¨Ù‚Ø© Ø´ÙØ§ÙØ©" if as_layer else ""),
                total_time=total_time,
                stage_times=stage_times,
                specialization=spec_name,
                is_video=is_video,
                output_data={"preview_path": preview_path}
            )

        except Exception as e:
            logger.exception("Ø®Ø·Ø£ ÙÙŠ generate_image")
            return GenerationResult(
                success=False,
                message=str(e),
                total_time=perf_counter() - start_total,
                stage_times=stage_times,
                specialization=spec_name,
                is_video=is_video
            )
 
    def _should_apply_physics(self, prompt: str, layers: list) -> bool:
        """Ù‚Ø±Ø§Ø± Ø¨Ø³ÙŠØ·: Ù‡Ù„ Ù†ÙØ¹Ù‘Ù„ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ Ø£Ù… Ù„Ø§ØŸ"""
        lower = prompt.lower()
        trigger_words = [
            "collide", "ØªØµØ§Ø¯Ù…", "interact", "ØªÙØ§Ø¹Ù„", "wind", "Ø±ÙŠØ§Ø­",
            "gravity", "Ø¬Ø§Ø°Ø¨ÙŠØ©", "fall", "Ø³Ù‚ÙˆØ·", "float", "Ø·ÙÙˆ",
            "multiple", "ÙƒØ«ÙŠØ±", "crowd", "Ø­Ø´Ø¯", "chaos", "ÙÙˆØ¶Ù‰", "physics"
        ]
        has_trigger = any(word in lower for word in trigger_words)
        many_layers = len(layers) >= 4
        return apply_physics or has_trigger or many_layers   # â† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ± Ø§Ù„Ø¹Ø§Ù…

    def _generate_environment_elements(
        self,
        prompt: str,
        resolution: tuple = (1024, 1024),
        output_name: Optional[str] = None,
        force_refresh: bool = False,
        is_video: bool = False,
        auto_split: bool = True,
        sequential_mode: bool = False,
        apply_physics: bool = False,
    ) -> GenerationResult:
        start_total = perf_counter()
        stage_times = {}
        intermediate = {"prompt_components": {}, "layer_results": {}, "enhanced_prompts": {}}
        plane_layers = []

        full_prompt = prompt.strip()

        # 1. Ø§Ù„ØªØ®Ø·ÙŠØ·
        if auto_split:
            try:
                plan = self.supervisor.plan_layers(full_prompt, mode="sequential" if sequential_mode else "parallel")
            except Exception as e:
                logger.warning(f"ÙØ´Ù„ Ø§Ù„ØªØ®Ø·ÙŠØ·: {e} â†’ ØªÙ‚Ø³ÙŠÙ… ÙŠØ¯ÙˆÙŠ")
                plan = {"background": full_prompt, "midground": full_prompt, "foreground": full_prompt}
        else:
            plan = {"background": full_prompt, "midground": full_prompt, "foreground": full_prompt}

        intermediate["prompt_components"] = plan

        # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØµØ§Ù…ÙŠÙ… (Design Phase) â€“ Ù„Ø§ Ù†ÙˆÙ„Ù‘Ø¯ ØµÙˆØ± Ù‡Ù†Ø§ Ø¨Ø¹Ø¯
        layer_results = {}
        plane_layers = []  # Ø³Ù†Ø¨Ù‚ÙŠÙ‡Ø§ Ù„Ùˆ ÙƒÙ†Øª Ù„Ø§ ØªØ²Ø§Ù„ ØªØ³ØªØ®Ø¯Ù… PlaneLayer Ù„Ù„ØªØ±ØªÙŠØ¨

        for layer_name, sub_prompt in plan.items():
            engine = self.engine_map.get(layer_name)
            if not engine:
                logger.error(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­Ø±Ùƒ Ù„Ù„Ø·Ø¨Ù‚Ø©: {layer_name}")
                continue

            logger.info(f"Ø¬Ø§Ø±ÙŠ ØªØµÙ…ÙŠÙ… Ø§Ù„Ø·Ø¨Ù‚Ø©: {layer_name} â†’ prompt: {sub_prompt[:60]}...")

            res = None

            # â”€â”€â”€ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                if layer_name == "background" and hasattr(engine, "design_environment_assets"):
                    # Ø§Ù„Ø¨ÙŠØ¦Ø© ØºØ§Ù„Ø¨Ø§Ù‹ Ù„Ù‡Ø§ Ø¯Ø§Ù„Ø© Ø®Ø§ØµØ© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹
                    res = engine.design_environment_assets(
                        prompt=sub_prompt,
                        resolution=resolution,
                        render_color=False,           # Ù…Ù‡Ù…: Ù„Ø§ Ù†Ø±ÙŠØ¯ ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†ØŒ ÙÙ‚Ø· Ø§Ù„ØªØµÙ…ÙŠÙ…
                        heightmap_format="npy",       # Ø£Ùˆ "exr" Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ø³ØªØ¹Ø¯
                        force_refresh=force_refresh
                    )

                elif hasattr(engine, "design"):
                    # Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØµÙ…ÙŠÙ… (geometric Ø£Ùˆ traditional Ø£Ùˆ fallback)
                    res = engine.design(
                        description=sub_prompt,
                        resolution=resolution,
                        force_refresh=force_refresh,
                        **kwargs
                    )

                else:
                    logger.warning(f"Ø§Ù„Ù…Ø­Ø±Ùƒ {layer_name} Ù„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø¯Ø§Ù„Ø© ØªØµÙ…ÙŠÙ… Ù…Ø¹Ø±ÙˆÙØ© â†’ ØªØ®Ø·ÙŠ")
                    continue

            except AttributeError as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ù€ {layer_name}: {e}")
                continue
            except Exception as e:
                logger.exception(f"Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ ØªØµÙ…ÙŠÙ… {layer_name}")
                continue

            if res and res.success:
                layer_results[layer_name] = res
                intermediate["enhanced_prompts"][layer_name] = res.output_data.get("enhanced_prompt", sub_prompt)

                # â”€â”€â”€ Ø¥Ù†Ø´Ø§Ø¡ PlaneLayer Ù„Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù„Ø§Ø­Ù‚ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                z_map = {"background": -1.0, "midground": 0.0, "foreground": 1.0}
                color_map = {"background": "navy", "midground": "teal", "foreground": "gold"}

                z_depth = z_map.get(layer_name, 0.0)
                p_layer = PlaneLayer(
                    position=[0.0, 0.0, z_depth],
                    force=1.0 if layer_name == "foreground" else 0.6 if layer_name == "midground" else 0.3,
                    depth=abs(z_depth) + 1.0,
                    label=layer_name.capitalize(),
                    color=color_map.get(layer_name, "gray"),
                    mass=10.0 if layer_name == "background" else 3.0
                )

                # Ø¨Ø¯Ù„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ preview_pathØŒ Ù†Ø¶Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØµÙ…ÙŠÙ…
                p_layer.metadata = {
                    "source": layer_name,
                    "design_result": res,
                    "assets_directory": res.output_data.get("assets_directory"),
                    "paths": res.output_data.get("paths", {}),
                    "elements_count": len(res.elements) if hasattr(res, "elements") else 0
                }

                plane_layers.append(p_layer)
            else:
                logger.warning(f"ØªØµÙ…ÙŠÙ… Ø§Ù„Ø·Ø¨Ù‚Ø© {layer_name} ÙØ´Ù„ â†’ Ù„Ù† ØªÙØ¶Ø§Ù")
        
        # 3. combined prompt
        combined_prompt = ", ".join(
            intermediate["enhanced_prompts"].get(l, "") for l in ["background", "midground", "foreground"]
        ).strip(", ") + ", highly detailed, cinematic lighting, professional composition, 8k"

        # 4. Ù‚Ø±Ø§Ø± Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡
        use_physics = apply_physics or self._should_apply_physics(full_prompt, plane_layers)

        if use_physics and plane_layers:
            try:
                composer = LayerComposer()
                adjusted = composer.adjust_layers_for_physics(
                    plane_layers,
                    prompt=full_prompt,
                    resolution=resolution,
                    collision_threshold=0.15,
                    emotional_amplifier=1.2
                )
                plane_layers = adjusted
                logger.info(f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ Ø¹Ù„Ù‰ {len(plane_layers)} Ø·Ø¨Ù‚Ø©")
            except Exception as e:
                logger.warning(f"ÙØ´Ù„ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡: {e} â†’ Ù†ÙƒÙ…Ù„ Ø¨Ø¯ÙˆÙ†Ù‡Ø§")
                use_physics = False

        # 5. Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ - placeholder Ù†ÙŠÙˆÙ† Ø¨Ø³ÙŠØ·
        from PIL import Image, ImageDraw, ImageFilter, ImageEnhance, ImageFont

        img = Image.new("RGB", resolution, (10, 5, 30))  # Ø®Ù„ÙÙŠØ© Ù†ÙŠÙˆÙ† Ø¯Ø§ÙƒÙ†Ø©
        draw = ImageDraw.Draw(img)

        # Ø®Ù„ÙÙŠØ© Ù†ÙŠÙˆÙ† (Ø®Ø·ÙˆØ· Ù…Ø¶ÙŠØ¦Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©)
        for _ in range(30):
            x1, y1 = random.randint(0, resolution[0]), random.randint(0, resolution[1])
            x2, y2 = random.randint(0, resolution[0]), random.randint(0, resolution[1])
            color = random.choice([(255, 50, 255), (50, 255, 255), (255, 255, 100), (100, 255, 255)])
            draw.line((x1, y1, x2, y2), fill=color, width=2)

        # Ø³ÙŠØ§Ø±Ø© Ø±ÙŠØ§Ø¶ÙŠØ© (ÙˆØ³Ø· Ø§Ù„ØµÙˆØ±Ø©)
        car_x, car_y = resolution[0]//2, resolution[1]//2 + 50
        draw.rectangle((car_x-120, car_y-40, car_x+120, car_y+40), fill=(200, 20, 80), outline=(255, 255, 255), width=3)
        draw.ellipse((car_x-100, car_y+20, car_x-60, car_y+60), fill=(50, 50, 50))  # Ø¹Ø¬Ù„Ø© ÙŠØ³Ø§Ø±
        draw.ellipse((car_x+60, car_y+20, car_x+100, car_y+60), fill=(50, 50, 50))  # Ø¹Ø¬Ù„Ø© ÙŠÙ…ÙŠÙ†
        draw.polygon([(car_x-80, car_y-40), (car_x, car_y-80), (car_x+80, car_y-40)], fill=(220, 40, 100))  # Ø³Ù‚Ù Ø§Ù„Ø³ÙŠØ§Ø±Ø©

        # ÙØªØ§Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© (Ø£Ø³ÙÙ„ Ø§Ù„ÙˆØ³Ø·)
        girl_x, girl_y = resolution[0]//2, resolution[1]-150
        draw.ellipse((girl_x-40, girl_y-80, girl_x+40, girl_y-20), fill=(240, 200, 180))  # ÙˆØ¬Ù‡
        draw.rectangle((girl_x-50, girl_y-20, girl_x+50, girl_y+100), fill=(150, 50, 200))  # Ø¬Ø³Ù…
        draw.line((girl_x-30, girl_y-60, girl_x-60, girl_y-20), fill=(200, 150, 255), width=10)  # Ø´Ø¹Ø± ÙŠØ³Ø§Ø±
        draw.line((girl_x+30, girl_y-60, girl_x+60, girl_y-20), fill=(200, 150, 255), width=10)  # Ø´Ø¹Ø± ÙŠÙ…ÙŠÙ†

        # Ù†Øµ ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰
        try:
            font = ImageFont.truetype("arial.ttf", 40)  # Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… default
        except:
            font = ImageFont.load_default()
        draw.text((50, 20), "Neon Cyberpunk Test â€“ Ù…Ø¶Ø±Ø³ Engine ğŸ˜", fill=(255, 100, 255), font=font)

        # ØªØ­Ø³ÙŠÙ†Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
        img = img.filter(ImageFilter.GaussianBlur(1.5))
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.4)

        final_path = output_name or f"composite_neon_test_{int(perf_counter()*1000)}.png"
        img.save(final_path)
        self.temp_files.append(final_path)
        
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _should_apply_physics(self, prompt: str, layers: list) -> bool:
        lower = prompt.lower()
        keywords = [
            "collide", "ØªØµØ§Ø¯Ù…", "interact", "ØªÙØ§Ø¹Ù„", "wind", "Ø±ÙŠØ§Ø­", 
            "gravity", "Ø¬Ø§Ø°Ø¨ÙŠØ©", "fall", "Ø³Ù‚ÙˆØ·", "float", "Ø·ÙÙˆ",
            "multiple", "ÙƒØ«ÙŠØ±", "crowd", "Ø­Ø´Ø¯", "chaos", "ÙÙˆØ¶Ù‰"
        ]
        has_trigger = any(k in lower for k in keywords)
        many_layers = len(layers) >= 4
        return has_trigger or many_layers
    
    def cleanup_temp_references(self):
            """
            Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù…Ø³Ø¬Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.
            - ÙŠÙØ³ØªØ¯Ø¹Ù‰ Ø¨Ø¹Ø¯ ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© ØªÙˆÙ„ÙŠØ¯ ÙƒØ§Ù…Ù„Ø© (Ù…Ø«Ù„ _generate_environment_elements)
            - Ø£Ùˆ ÙÙŠ __del__ / context manager exit
            - Ø¢Ù…Ù† ÙˆÙŠÙØ³Ø¬Ù„ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ§Øª ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡
            """
            if not hasattr(self, 'temp_files') or not self.temp_files:
                logger.debug("[Cleanup] Ù„Ø§ Ù…Ù„ÙØ§Øª Ù…Ø¤Ù‚ØªØ© Ù…Ø³Ø¬Ù„Ø©")
                return

            deleted_count = 0
            failed_count = 0
            temp_list = self.temp_files.copy()  # Ù†Ø³Ø®Ø© Ø¢Ù…Ù†Ø©

            for path in temp_list:
                path_str = str(path)  # Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ string
                if os.path.exists(path_str):
                    try:
                        if os.path.isfile(path_str):
                            os.remove(path_str)
                        elif os.path.isdir(path_str):
                            import shutil
                            shutil.rmtree(path_str, ignore_errors=True)
                        else:
                            logger.warning(f"[Cleanup] Ù†ÙˆØ¹ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {path_str}")
                            continue

                        logger.debug(f"[Cleanup] ØªÙ… Ø­Ø°Ù: {path_str}")
                        deleted_count += 1
                        self.temp_files.remove(path)  # Ø­Ø°Ù Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©

                    except PermissionError:
                        logger.warning(f"[Cleanup] Ø±ÙØ¶ Ø§Ù„Ø¥Ø°Ù† Ù„Ø­Ø°Ù: {path_str}")
                        failed_count += 1
                    except FileNotFoundError:
                        logger.debug(f"[Cleanup] Ø§Ù„Ù…Ù„Ù Ø§Ø®ØªÙÙ‰ Ø¨Ø§Ù„ÙØ¹Ù„: {path_str}")
                        self.temp_files.remove(path)
                    except Exception as e:
                        logger.warning(f"[Cleanup] ÙØ´Ù„ Ø­Ø°Ù {path_str}: {type(e).__name__} - {e}")
                        failed_count += 1

            if deleted_count > 0 or failed_count > 0:
                logger.info(
                    f"[Cleanup] ØªÙ… Ø­Ø°Ù {deleted_count} Ù…Ù„Ù/Ù…Ø¬Ù„Ø¯ | ÙØ´Ù„ {failed_count} | Ø¨Ø§Ù‚ÙŠ {len(self.temp_files)}"
                )
            else:
                logger.debug("[Cleanup] Ù„Ø§ Ù…Ù„ÙØ§Øª ØªØ­ØªØ§Ø¬ Ø­Ø°Ù")
        
    def generate_layer(
        self,
        prompt: str,
        target_size: tuple = (1024, 1024),
        is_video: bool = False,
        as_layer: bool = True,
        force_refresh: bool = False,
        **kwargs
    ) -> GenerationResult:
        """
        ØªÙ†ÙÙŠØ° Ø¨Ø³ÙŠØ· Ù„ØªÙˆÙ„ÙŠØ¯ Ø·Ø¨Ù‚Ø© ÙˆØ§Ø­Ø¯Ø© (placeholder Ù…Ø¤Ù‚Øª)
        Ø¨Ø¹Ø¯ÙŠÙ† Ù‡Ù†Ø±Ø¨Ø·Ù‡Ø§ Ø¨Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù…Ù† engine_map
        """
        logger.info(f"[generate_layer] prompt: {prompt[:70]}...")

        # Ù†ØªÙŠØ¬Ø© ÙˆÙ‡Ù…ÙŠØ© Ø¹Ø´Ø§Ù† Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ¹Ø¯ÙŠ
        fake_path = f"temp_layer_{int(perf_counter()*1000)}.png"

        return GenerationResult(
            success=True,
            message="Ø·Ø¨Ù‚Ø© Ù…ÙˆÙ„Ø¯Ø© (placeholder â€“ Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø¹Ø¯)",
            total_time=0.42,
            stage_times={"analysis": 0.1, "render": 0.32},
            specialization=self.specialization,
            is_video=is_video,
            output_data={
                "preview_path": fake_path,
                "layer_type": "placeholder_layer"
            }
        )
        
    def _get_specialization_config(self) -> Dict[str, Any]:
        return {"name": "composite", "description": "layer compositor"}

    def _analyze_prompt(self, prompt: str) -> Dict[str, Any]:
        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ù‹Ø§ Ø£Ùˆ placeholder
        return {"entities": prompt.split(), "style": "composite"}

    def _integrate(self, task_data: Dict) -> float:
        # ÙˆÙ‚Øª ÙˆÙ‡Ù…ÙŠ Ù„Ù„ØªÙƒØ§Ù…Ù„
        return 0.45

    def _post_process(self, task_data: Dict) -> Dict[str, Any]:
        return {"processed": True, "message": "post-processing placeholder"}

    def _render(self, task_data: Dict, is_video: bool = False) -> float:
        # ÙˆÙ‚Øª ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ù€ render
        return 1.2

    def _render_design_placeholder(self, design_data: dict, resolution: tuple, layer_name: str = "unknown") -> Image.Image:
        """
        ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© placeholder Ø¨Ø³ÙŠØ·Ø© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØµÙ…ÙŠÙ… ÙÙ‚Ø·
        (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ù„ØªØµØ¨Ø­ Ø±Ø³Ù…Ù‹Ø§ Ø£ÙƒØ«Ø± Ø°ÙƒØ§Ø¡Ù‹)
        """
        img = Image.new("RGBA", resolution, (10, 15, 30, 255))  # Ø®Ù„ÙÙŠØ© Ø¯Ø§ÙƒÙ†Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        draw = ImageDraw.Draw(img)

        # Ù†Øµ ØªÙˆØ¶ÙŠØ­ÙŠ ÙƒØ¨ÙŠØ±
        try:
            font = ImageFont.truetype("arial.ttf", 60)
        except:
            font = ImageFont.load_default()

        draw.text(
            (50, 50),
            f"{layer_name.upper()} Design Placeholder\n"
            f"Elements: {design_data.get('elements_count', 0)}\n"
            f"Assets: {design_data.get('assets_dir', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')}",
            fill=(220, 180, 100),
            font=font
        )

        # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ heightmapØŒ Ù†Ø±Ø³Ù…Ù‡ ÙƒØªØ¯Ø±Ø¬ Ø¨Ø³ÙŠØ·
        if "paths" in design_data and "heightmap" in design_data["paths"]:
            hmap_path = design_data["paths"]["heightmap"]
            if os.path.exists(hmap_path):
                try:
                    hmap = np.load(hmap_path)
                    hmap = (hmap * 255).astype(np.uint8)
                    hmap_img = Image.fromarray(hmap, mode="L").convert("RGBA")
                    hmap_img = hmap_img.resize(resolution)
                    draw_img = ImageDraw.Draw(hmap_img)
                    draw_img.text((20, 20), "Heightmap Preview", fill=(255, 100, 100))
                    img = Image.alpha_composite(img, hmap_img)
                except:
                    pass

        return img
    
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    logger.info("=== Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± CompositeEngine ===")

    try:
        engine = CompositeEngine()
        logger.info("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ CompositeEngine Ø¨Ù†Ø¬Ø§Ø­")

        # Ø§Ø®ØªØ¨Ø§Ø± 1: ØªÙˆÙ„ÙŠØ¯ Ø·Ø¨Ù‚Ø© ÙˆØ§Ø­Ø¯Ø© (Ø¨Ø³ÙŠØ·)
        print("\n=== Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ø·Ø¨Ù‚Ø© ÙˆØ§Ø­Ø¯Ø© ===")
        layer_result = engine.generate_layer(
            prompt="ØºØ§Ø¨Ø© Ø³Ø­Ø±ÙŠØ© Ù…Ø¹ Ø¶Ø¨Ø§Ø¨ ÙˆØ£Ø¶ÙˆØ§Ø¡ Ø®Ø§ÙØªØ©",
            target_size=(512, 512),
            as_layer=True,
            force_refresh=True
        )
        print("Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø·Ø¨Ù‚Ø©:", layer_result)

        # Ø§Ø®ØªØ¨Ø§Ø± 2: Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙˆÙ„ÙŠØ¯ Ù…Ø±ÙƒØ¨ ÙƒØ§Ù…Ù„
        print("\n=== Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ù…Ø±ÙƒØ¨ ÙƒØ§Ù…Ù„ ===")
        composite_result = engine._generate_environment_elements(
            prompt="ÙØªØ§Ø© ØªÙ‚Ù ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù†ÙŠÙˆÙ† Ù„ÙŠÙ„ÙŠØ© Ù…Ø¹ Ø³ÙŠØ§Ø±Ø© Ø±ÙŠØ§Ø¶ÙŠØ© ÙˆØ£Ù†Ù…Ø§Ø· Ù‡Ù†Ø¯Ø³ÙŠØ© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©",
            resolution=(768, 768),
            output_name="test_composite_output.png",
            force_refresh=True,
            is_video=False,
            auto_split=True
        )
        print("Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø±ÙƒØ¨:", composite_result)

        # Ø§Ø®ØªØ¨Ø§Ø± 3: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        print("\n=== ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© ===")
        engine.cleanup_temp_references()
        print("ØªÙ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ")

    except Exception as e:
        logger.exception("Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± CompositeEngine")
        print(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

    finally:
        logger.info("=== Ø§Ù†ØªÙ‡Ù‰ Ø§Ø®ØªØ¨Ø§Ø± CompositeEngine ===")